---
title: "Test (easy)"
author: "Alessandro De Bettin"
date: "20 marzo 2016"
output: pdf_document
---

##Errors and Cross-Validation

First off, I need to write a function that computes the desired test error. It is the following. Since the data I'll consider have only one type of censoring, I decided to use as an input to the function an object of class "Surv" ("survival" package); this is a quick and easy way to handle right censoring. The function outputs the sum of all errors.

```{r}
surv.loss <- function(observed,predicted){ #observed is an object of type Surv
  loss <- rep(0,length(predicted))
  loss[observed[,2] == 0] <- as.numeric(predicted[observed[,2] == 0] <     observed[observed[,2] == 0,1]) #error, uncensored
  loss[observed[,2] == 1] <- as.numeric((predicted[observed[,2] == 1] < observed[observed[,2] == 1,1]/2) |
                                          (predicted[observed[,2] == 1] > observed[observed[,2] == 1,1]*2)) #error, censored
  sum(loss)
}
```
```{r}
surv.loss2 <- function(observed,predicted){ #observed is an object of type Surv, predicted is a matrix
  if(is.vector(predicted)) surv.loss(observed,predicted)
  else
  {
    loss <- matrix(0,nrow=nrow(predicted),ncol=ncol(predicted))
    loss[observed[,2] == 0,] <- as.numeric(predicted[observed[,2] == 0,] < observed[observed[,2] == 0,1]) 
    loss[observed[,2] == 1,] <- as.numeric((predicted[observed[,2] == 1,] < observed[observed[,2] == 1,1]/2) |
                                             (predicted[observed[,2] == 1,] > observed[observed[,2] == 1,1]*2))
    loss 
  }
}
```

"surv.loss2" is the same but can handle matrices of predictions (every column is the prediction of a different model).

I need to write some functions to implement a cross-validation procedure. The first one has the task of splitting the indexes of the observations into "nfold" parts, outputting a list of "nfold" elements each of which is a vector of indexes.

```{r}
cv.index <- function(data,nfold){
  n <- nrow(data)
  split(sample(1:n), rep(1:nfold, length = n))
}
```

The next function computes the cross-validated error for models fitted with the "survreg" function of the "survival" package. The inputs are: the distribution of the response, the data-frame of the explanatory variables, the response variable (of class "Surv") and the number of folds used for the cross-validation. The output is the sum of the errors the procedure makes in each of the "nfold" steps of the cross-validation.

```{r}
surv.cv <- function(dist,X,y,nfold){
  index <- cv.index(cbind(X,y),nfold)
  err <- rep(0,nfold)
  for(i in 1:nfold){
    mod <- survreg(y[-index[[i]]]~.,data=X[-index[[i]],],dist=dist)
    err[i] <- surv.loss(y[index[[i]]],predict(mod,newdata=X[index[[i]],]))
  }
  sum(err)
}
```

Then, I need a function for estimating the cross-validated error using the adaptive elastic-net AFT model of the "AdapEnetClass" package. The package has a built-in cross-validation function with mean of squared error loss. The function is the following.

```{r,include=FALSE}
library(AdapEnetClass)
```
```{r}
cv.AWEnet
```

Running the code on the data used in the package example I noticed that the cross-validation would always suggest the same choice for the penalty tuning parameter; that didn't make sense, so I read all the function throughout, and I noticed that at each cross-validation step the model would be estimated on all of the data. Doing so, the function does not compute an estimate of the cross-validated error, but of the training error. So, I modified the function in order to make a proper cross-validation, using the error loss function that I had already written. I marked with a "#" the modified lines.

```{r}
cv.AWEnet2 <- function (X, Y, delta, weight, lambda2, maxit, K = 10, fraction = seq(from = 0, 
                                                                                    to = 1, length = 100), plot.it = F, se = TRUE, AEnet = T, 
                        all.folds = NULL) 
{
  require(survival) #
  bds <- sort(lambda2)
  cv.Enet <- function(X, Y, delta, weight, lambda2, maxit, 
                      K, fraction, AEnet) {
    if (is.null(all.folds)) 
      all.folds <- cv.folds(length(Y), K)
    residmat <- matrix(0, length(fraction), K)
    for (i in seq(K)) {
      omit <- all.folds[[i]]
      if (AEnet) 
        fit <- AEnet.aft(X[-omit,], Y[-omit], delta[-omit], weight, lambda2, #
                         maxit)
      else fit <- WEnet.aft(X[-omit,], Y[-omit], delta[-omit], weight, lambda2, #
                            maxit)
      fit <- predict(fit, X[omit, , drop = FALSE], mode = "fraction", 
                     s = fraction)$fit
      if (length(omit) == 1) 
        fit <- matrix(fit, nrow = 1)
      residmat[, i] <- apply(surv.loss2(Surv(Y[omit],delta[omit]),fit),2,sum) #
    }
    cv <- apply(residmat, 1, sum) #
    cv.error <- sqrt(K*apply(residmat, 1, var)) #
    object <- list(index = fraction, cv = cv, cv.error = cv.error, 
                   all.folds = all.folds, mode = "fraction")
    if (plot.it) 
      plotCVLars(object, se = se)
    invisible(object)
  }
  index <- NULL
  for (lambda in bds) {
    if (AEnet) {
      cvEnet <- cv.Enet(X, Y, delta, weight, lambda, maxit, 
                        K, fraction, AEnet = T)
      s <- cvEnet$index[which.min(cvEnet$cv)]
      cv.mse <- which.min(cvEnet$cv)
      cv.error <- which.min(cvEnet$cv.error)
      index <- rbind(index, c(lambda, s, cv.mse, cv.error))
    }
    else {
      cvEnet <- cv.Enet(X, Y, delta, weight, lambda, maxit, 
                        K, fraction, AEnet = F)
      gama <- cvEnet$index[which.min(cvEnet$cv)]
      s <- gama * sqrt(1 + lambda)
      cv.mse <- which.min(cvEnet$cv)
      cv.error <- which.min(cvEnet$cv.error)
      index <- rbind(index, c(lambda, s, cv.mse, cv.error))
    }
  }
  list(index = index,cv=cvEnet$cv[index[3]]) # #cv in order to compare with other models
}

```

My version of the cross-validation function outputs also an estimate of the cross-validation error relative to the model with the optimal tuning parameter, in order to make model comparison easy. As for the cross-validation function for "survreg" models, the error is calculated summing the "nfold" errors.

##Examples

###Lung dataset

```{r}
library(survival)

dati <- lung

dati$inst <- NULL #not worth it

dati$status <- as.factor(dati$status) #these are factors
dati$sex <- as.factor(dati$sex)
```

The "inst" variable is a factor with many levels, using it as a predictor would not be worth it (the data-set does not contain enough observations) therefore I eliminate it. "status" represents the censoring; even though it is not necessary I prefer to transform it to a factor. "sex" is definitely not a numerical variable. The data-set contains some NAs. Since NAs are not too many, I decide to substitute them with the mean of the variable they are relative to. This should minimize the information loss.

```{r}
dati$ph.ecog[is.na(dati$ph.ecog)] <- mean(dati$ph.ecog, na.rm = TRUE)
dati$ph.karno[is.na(dati$ph.karno)] <- mean(dati$ph.karno, na.rm = TRUE)
dati$pat.karno[is.na(dati$pat.karno)] <- mean(dati$pat.karno, na.rm = TRUE)
dati$meal.cal[is.na(dati$meal.cal)] <- mean(dati$meal.cal, na.rm = TRUE)
dati$wt.loss[is.na(dati$wt.loss)] <- mean(dati$wt.loss, na.rm = TRUE)
```

It is now time to fit some models. First, let's create a "Surv" object containing the observed values.

```{r}
y <- Surv(dati$time,event = dati$status==2)
```

The first model I estimate is a Weibull one.

```{r}
sf1 <- survreg(y~.,data=dati[,-c(1,2)],dist="weibull") #weibull model
summary(sf1)
```

"meal.cal" and "wt.loss"" are non significant, since they bring similar information, I might remove one of them. 

```{r}
anova(sf1,survreg(y~.,data=dati[,-c(1,2,8)],dist="weibull")) #I remove meal.cal, the one with more NAs

dati$meal.cal <- NULL
```

The anova test suggests that the model fitted without "meal.cal" is statistically equivalent to the former. For the moment I eliminate just one variable: "meal.cal"; I choose this one because it is the variable with the biggest number of NAs.

Now we have a set of explanatory variables, so let's fit various models using the "survreg" function.

Estimates of the cross-validated error are the following.

```{r}
set.seed(313)
surv.cv("weibull",dati[,-c(1,2)],y,5)
surv.cv("exponential",dati[,-c(1,2)],y,5)
surv.cv("loglogistic",dati[,-c(1,2)],y,5) #best model
surv.cv("lognormal",dati[,-c(1,2)],y,5)
```

The log-logistic model seems to be the winner. Let's try to improve the model by removing non significant variables.

```{r}
sf3 <- survreg(y~.,data=dati[,-c(1,2)],dist="loglogistic")
summary(sf3)
surv.cv("loglogistic",dati[,-c(1,2,3,6,8)],y,5)
```

Now, let's make a confrontation with the adaptive elastic-net model. The initial weights are estimated using the Buckley-James method.

```{r}
X <- model.matrix(y~.,data=dati[,-c(1,2)])[,-1]

l<-mrbj(cbind(y[,1], y[,2]) ~ X, mcsize=100, trace=FALSE, gehanonly=FALSE)

cv.AWEnet2(X,y[,1],y[,2],l$enet,3,10,5)
```

The model is not better than the log-logistic one.

###Ovarian data

```{r}
dati <- ovarian
```

The description of the data suggests to transform some variables into factors.

```{r}
dati$fustat <- factor(dati$fustat)
dati$resid.ds <- factor(dati$resid.ds)
dati$rx <- factor(dati$rx)
dati$ecog.ps <- factor(dati$ecog.ps)
```

These are the cross-validated errors for the "survfit" models.

```{r}
y <- Surv(dati$futime,event = dati$fustat == 1)

surv.cv("weibull",dati[,-c(1,2)],y,10) 
surv.cv("exponential",dati[,-c(1,2)],y,10)
surv.cv("loglogistic",dati[,-c(1,2)],y,10) 
surv.cv("lognormal",dati[,-c(1,2)],y,10) #winner
```

I choose a 10-fold cross-validation. In this case the best model appears to be the log-normal one.

###MCLcleaned data

Since the number of predictors is bigger than the number of observations, I can only fit the elastic-net AFT model. The "ID" is not useful in this situation, therefore I remove it.

```{r}
utils::data(MCLcleaned, package="AdapEnetClass")

dati <- MCLcleaned

dati$ID <- NULL

y <- Surv(dati$time,event = dati$cens)

X <- model.matrix(y~.,data=dati[,-c(1,2)])[,-1]
```

The initial weigths are calculated with the "Enet.wls" function. I now estimate the error using a few values for the ridge penalization.

```{r}
wt <- Enet.wls(X,y[,1],y[,2])$beta
lambda2 <- c(15,20,25)
sapply(lambda2, function(x) cv.AWEnet2(X,y[,1],y[,2],wt,x,10)$cv)
```





